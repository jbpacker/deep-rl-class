{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HuggingFace Unit 4 üî•.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP3U1be/7FIwY+FlWCQK67a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbpacker/deep-rl-class/blob/main/unit4/HuggingFace_Unit_4_%F0%9F%94%A5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit 4: Let's learn about Unity ML-Agents with Hugging Face ü§ó\n",
        "\n",
        "original colab can be found here: https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/unit4/unit4.ipynb#scrollTo=C9Ls6_6eOKiA"
      ],
      "metadata": {
        "id": "DodtFJWU47xs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites üèóÔ∏è"
      ],
      "metadata": {
        "id": "yYk-BXWh5BB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Clone the repository and install the dependencies üîΩ\n"
      ],
      "metadata": {
        "id": "X-vxkAAk5C60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Clone the repository (can take 1min)\n",
        "!git clone https://github.com/huggingface/ml-agents/"
      ],
      "metadata": {
        "id": "55Bzu8Fg5FjV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Go inside the repository and install the package\n",
        "%cd ml-agents\n",
        "!pip3 install -e ./ml-agents-envs\n",
        "!pip3 install -e ./ml-agents"
      ],
      "metadata": {
        "id": "p2xs53_z5SVQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./trained-envs-executables\n",
        "!mkdir ./trained-envs-executables/linux"
      ],
      "metadata": {
        "id": "r7RNy58V5Ty4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Download and move the environment zip file in `./\n"
      ],
      "metadata": {
        "id": "F5BZYZ7b5Cuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UiFNdKlsH0NTu32xV-giYUEVKV4-vc7H' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1UiFNdKlsH0NTu32xV-giYUEVKV4-vc7H\" -O ./trained-envs-executables/linux/Pyramids.zip && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "id": "9hu5pNAn5Cb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5CyGbWpU4saV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!unzip -d ./trained-envs-executables/linux/ ./trained-envs-executables/linux/Pyramids.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "make sure it's accessible"
      ],
      "metadata": {
        "id": "AbTfe7xT5izo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod -R 755 ./trained-envs-executables/linux/Pyramids/Pyramids"
      ],
      "metadata": {
        "id": "kAmsP_sv5iXw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Modify the PyramidsRND config file\n",
        "\n",
        "Click here to open the config.yaml: /content/ml-agents/config/ppo/PyramidsRND.yaml\n",
        "Modify the max_steps to 500,000"
      ],
      "metadata": {
        "id": "apwdvJJM5qFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train our agent\n"
      ],
      "metadata": {
        "id": "SN3lvW_w6xa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-learn ./config/ppo/PyramidsRND.yaml --env=./trained-envs-executables/linux/Pyramids/Pyramids --run-id=\"Pyramids Training\" --no-graphics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AjW77Ue61ro",
        "outputId": "ff1d3169-f0e6-4a22-813d-a524666d163b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "            ‚îê  ‚ïñ\n",
            "        ‚ïì‚ïñ‚ï¨‚îÇ‚ï°  ‚îÇ‚îÇ‚ï¨‚ïñ‚ïñ\n",
            "    ‚ïì‚ïñ‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚îò  ‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚ï¨‚ïñ\n",
            " ‚ïñ‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚ï¨‚ïú        ‚ïô‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚ïñ‚ïñ                               ‚ïó‚ïó‚ïó\n",
            " ‚ï¨‚ï¨‚ï¨‚ï¨‚ïñ‚îÇ‚îÇ‚ï¶‚ïñ        ‚ïñ‚ï¨‚îÇ‚îÇ‚ïó‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£             ‚ïú‚ïú‚ïú  ‚ïü‚ï£‚ï£\n",
            " ‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ïñ‚îÇ‚ï¨‚ïñ‚ïñ‚ïì‚ï¨‚ï™‚îÇ‚ïì‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£ ‚ïí‚ï£‚ï£‚ïñ‚ïó‚ï£‚ï£‚ï£‚ïó   ‚ï£‚ï£‚ï£ ‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£ ‚ïü‚ï£‚ï£‚ïñ   ‚ï£‚ï£‚ï£\n",
            " ‚ï¨‚ï¨‚ï¨‚ï¨‚îê  ‚ïô‚ï¨‚ï¨‚ï¨‚ï¨‚îÇ‚ïì‚ï£‚ï£‚ï£‚ïù‚ïú  ‚ï´‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£ ‚ïü‚ï£‚ï£‚ï£‚ïô ‚ïô‚ï£‚ï£‚ï£  ‚ï£‚ï£‚ï£ ‚ïô‚ïü‚ï£‚ï£‚ïú‚ïô  ‚ï´‚ï£‚ï£  ‚ïü‚ï£‚ï£\n",
            " ‚ï¨‚ï¨‚ï¨‚ï¨‚îê     ‚ïô‚ï¨‚ï¨‚ï£‚ï£      ‚ï´‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£ ‚ïü‚ï£‚ï£‚ï¨   ‚ï£‚ï£‚ï£  ‚ï£‚ï£‚ï£  ‚ïü‚ï£‚ï£     ‚ï£‚ï£‚ï£‚îå‚ï£‚ï£‚ïú\n",
            " ‚ï¨‚ï¨‚ï¨‚ïú       ‚ï¨‚ï¨‚ï£‚ï£      ‚ïô‚ïù‚ï£‚ï£‚ï¨      ‚ïô‚ï£‚ï£‚ï£‚ïó‚ïñ‚ïì‚ïó‚ï£‚ï£‚ï£‚ïú ‚ïü‚ï£‚ï£‚ï¨   ‚ï£‚ï£‚ï£  ‚ï£‚ï£‚ï£  ‚ïü‚ï£‚ï£‚ï¶‚ïì    ‚ï£‚ï£‚ï£‚ï£‚ï£\n",
            " ‚ïô   ‚ïì‚ï¶‚ïñ    ‚ï¨‚ï¨‚ï£‚ï£   ‚ïì‚ïó‚ïó‚ïñ            ‚ïô‚ïù‚ï£‚ï£‚ï£‚ï£‚ïù‚ïú   ‚ïò‚ïù‚ïù‚ïú   ‚ïù‚ïù‚ïù  ‚ïù‚ïù‚ïù   ‚ïô‚ï£‚ï£‚ï£    ‚ïü‚ï£‚ï£‚ï£\n",
            "   ‚ï©‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¶‚ï¶‚ï¨‚ï¨‚ï£‚ï£‚ïó‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ïù                                             ‚ï´‚ï£‚ï£‚ï£‚ï£\n",
            "      ‚ïô‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ïù‚ïú\n",
            "          ‚ïô‚ï¨‚ï¨‚ï¨‚ï£‚ï£‚ï£‚ïú\n",
            "             ‚ïô\n",
            "        \n",
            " Version information:\n",
            "  ml-agents: 0.29.0.dev0,\n",
            "  ml-agents-envs: 0.29.0.dev0,\n",
            "  Communicator API: 1.5.0,\n",
            "  PyTorch: 1.8.1+cu102\n",
            "E0805 07:32:27.015882004     265 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n",
            "[INFO] Connected to Unity environment with package version 2.2.1-exp.1 and communication version 1.5.0\n",
            "[INFO] Connected new brain: Pyramids?team=0\n",
            "[INFO] Hyperparameters for behavior name Pyramids: \n",
            "\ttrainer_type:\tppo\n",
            "\thyperparameters:\t\n",
            "\t  batch_size:\t128\n",
            "\t  buffer_size:\t2048\n",
            "\t  learning_rate:\t0.0003\n",
            "\t  beta:\t0.01\n",
            "\t  epsilon:\t0.2\n",
            "\t  lambd:\t0.95\n",
            "\t  num_epoch:\t3\n",
            "\t  learning_rate_schedule:\tlinear\n",
            "\t  beta_schedule:\tlinear\n",
            "\t  epsilon_schedule:\tlinear\n",
            "\tnetwork_settings:\t\n",
            "\t  normalize:\tFalse\n",
            "\t  hidden_units:\t512\n",
            "\t  num_layers:\t2\n",
            "\t  vis_encode_type:\tsimple\n",
            "\t  memory:\tNone\n",
            "\t  goal_conditioning_type:\thyper\n",
            "\t  deterministic:\tFalse\n",
            "\treward_signals:\t\n",
            "\t  extrinsic:\t\n",
            "\t    gamma:\t0.99\n",
            "\t    strength:\t1.0\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t128\n",
            "\t      num_layers:\t2\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\t  rnd:\t\n",
            "\t    gamma:\t0.99\n",
            "\t    strength:\t0.01\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t64\n",
            "\t      num_layers:\t3\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\t    learning_rate:\t0.0001\n",
            "\t    encoding_size:\tNone\n",
            "\tinit_path:\tNone\n",
            "\tkeep_checkpoints:\t5\n",
            "\tcheckpoint_interval:\t500000\n",
            "\tmax_steps:\t500000\n",
            "\ttime_horizon:\t128\n",
            "\tsummary_freq:\t30000\n",
            "\tthreaded:\tFalse\n",
            "\tself_play:\tNone\n",
            "\tbehavioral_cloning:\tNone\n"
          ]
        }
      ]
    }
  ]
}