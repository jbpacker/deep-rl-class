{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HuggingFace unit 5 💪.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWFKON+JWUD/GL2oIAc48U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a8150e8249024d6ca524f16e50038033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e64df972301441ddbe86aac7b5232a2f",
              "IPY_MODEL_e7fc5b4efdc642c3ab32b41b4d967088"
            ],
            "layout": "IPY_MODEL_652af0b54229403387bfed60d739d3c1"
          }
        },
        "e64df972301441ddbe86aac7b5232a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d883f1908d834a4ebc0fbcf62c90ef7f",
            "placeholder": "​",
            "style": "IPY_MODEL_4785554bed9144bf9a4f2f7b3154906c",
            "value": "0.016 MB of 0.016 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "e7fc5b4efdc642c3ab32b41b4d967088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6d6f3c439cf4359905f2beb921d6c90",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1679a6e98d8a494099afcce71e880eec",
            "value": 1
          }
        },
        "652af0b54229403387bfed60d739d3c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d883f1908d834a4ebc0fbcf62c90ef7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4785554bed9144bf9a4f2f7b3154906c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6d6f3c439cf4359905f2beb921d6c90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1679a6e98d8a494099afcce71e880eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbpacker/deep-rl-class/blob/main/unit5/HuggingFace_unit_5_%F0%9F%92%AA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit 5: Code your first Deep Reinforcement Learning Algorithm with PyTorch: Reinforce. And test its robustness 💪\n",
        "\n",
        "link to [original colab](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/unit5/unit5.ipynb)\n",
        "\n",
        "🎮 Environments: \n",
        "- [CartPole-v1](https://www.gymlibrary.ml/environments/classic_control/cart_pole/)\n",
        "- [PixelCopter](https://pygame-learning-environment.readthedocs.io/en/latest/user/games/pixelcopter.html)\n",
        "- [Pong](https://pygame-learning-environment.readthedocs.io/en/latest/user/games/pong.html)"
      ],
      "metadata": {
        "id": "qEgrTLYVB1ls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## get everything ready"
      ],
      "metadata": {
        "id": "vuY-ey8mEsOg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: install libraries"
      ],
      "metadata": {
        "id": "n1g8AqnDFKhJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meyEc8YYAFvX",
        "outputId": "16c76959-7610-404c-970b-bd55b0e3c354"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.11-0ubuntu0.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.11).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (3.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f32f01cae50>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay\n",
        "\n",
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(500, 500))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym\n",
        "!pip install git+https://github.com/ntasfi/PyGame-Learning-Environment.git\n",
        "!pip install git+https://github.com/qlan3/gym-games.git\n",
        "!pip install huggingface_hub\n",
        "!pip install wandb\n",
        "\n",
        "!pip install pyyaml==6.0 # avoid key error metadata\n",
        "\n",
        "!pip install pyglet # Virtual Screen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-V9r6l7EwLd",
        "outputId": "7e269853-f51b-4d8e-8d7b-85b31a935a9a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.7.3)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.6)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/ntasfi/PyGame-Learning-Environment.git\n",
            "  Cloning https://github.com/ntasfi/PyGame-Learning-Environment.git to /tmp/pip-req-build-gcsoo98v\n",
            "  Running command git clone -q https://github.com/ntasfi/PyGame-Learning-Environment.git /tmp/pip-req-build-gcsoo98v\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ple==0.0.1) (1.21.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from ple==0.0.1) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/qlan3/gym-games.git\n",
            "  Cloning https://github.com/qlan3/gym-games.git to /tmp/pip-req-build-9n7irwjl\n",
            "  Running command git clone -q https://github.com/qlan3/gym-games.git /tmp/pip-req-build-9n7irwjl\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.7/dist-packages (from gym-games==1.0.4) (1.21.6)\n",
            "Requirement already satisfied: MinAtar>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from gym-games==1.0.4) (1.0.10)\n",
            "Requirement already satisfied: gym>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from gym-games==1.0.4) (0.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.1 in /usr/local/lib/python3.7/dist-packages (from gym-games==1.0.4) (57.4.0)\n",
            "Requirement already satisfied: pygame>=1.9.6 in /usr/local/lib/python3.7/dist-packages (from gym-games==1.0.4) (2.1.2)\n",
            "Requirement already satisfied: ple>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from gym-games==1.0.4) (0.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.13.0->gym-games==1.0.4) (1.7.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.13.0->gym-games==1.0.4) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.13.0->gym-games==1.0.4) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from MinAtar>=1.0.4->gym-games==1.0.4) (0.11.0)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.7/dist-packages (from MinAtar>=1.0.4->gym-games==1.0.4) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from MinAtar>=1.0.4->gym-games==1.0.4) (2.8.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from MinAtar>=1.0.4->gym-games==1.0.4) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from MinAtar>=1.0.4->gym-games==1.0.4) (1.4.4)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from MinAtar>=1.0.4->gym-games==1.0.4) (1.3.5)\n",
            "Requirement already satisfied: seaborn>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from MinAtar>=1.0.4->gym-games==1.0.4) (0.11.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.7/dist-packages (from MinAtar>=1.0.4->gym-games==1.0.4) (2022.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from MinAtar>=1.0.4->gym-games==1.0.4) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->MinAtar>=1.0.4->gym-games==1.0.4) (4.1.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from ple>=0.0.1->gym-games==1.0.4) (7.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.13.0->gym-games==1.0.4) (0.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.7.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.12.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface_hub) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface_hub) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.13.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.3.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.9.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.9)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml==6.0 in /usr/local/lib/python3.7/dist-packages (6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyglet in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: import packages"
      ],
      "metadata": {
        "id": "ypjCW-fTFMLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "import wandb\n",
        "\n",
        "import gym\n",
        "import gym_pygame\n",
        "\n",
        "from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\n",
        "\n",
        "import imageio"
      ],
      "metadata": {
        "id": "XtkJaB0sE7lA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "will print the device to be used"
      ],
      "metadata": {
        "id": "aRntyIXBFO4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKYKtRNvE-bt",
        "outputId": "02f2d2e4-2929-405e-afff-99e7795fc598"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Architecture"
      ],
      "metadata": {
        "id": "azRPyTwAFWYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Create the CartPole environment and understand how it works\n",
        "#### [The environment 🎮](https://www.gymlibrary.ml/environments/classic_control/cart_pole/)"
      ],
      "metadata": {
        "id": "-68RaZecFTpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_id = \"CartPole-v1\"\n",
        "env = gym.make(env_id)\n",
        "\n",
        "num_obs = env.observation_space.shape[0]\n",
        "num_act = env.action_space.n"
      ],
      "metadata": {
        "id": "lB6JBYsbFjlA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Model\n",
        "\n",
        "fully connected nn obs input and action output"
      ],
      "metadata": {
        "id": "pjJasbwSGy2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, num_obs, num_act):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "\n",
        "        self.l1 = nn.Linear(num_obs, 64)\n",
        "        self.dropout = nn.Dropout(p=0.6)\n",
        "        self.l2 = nn.Linear(64, num_act)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.l1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(x)\n",
        "        action_scores = self.l2(x)\n",
        "        action_probs = F.softmax(action_scores, dim=1)\n",
        "\n",
        "        return action_probs\n",
        "\n",
        "    def act(self, state):\n",
        "        \"\"\"\n",
        "        Given a state, take action\n",
        "        \"\"\"\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0)\n",
        "        probs = self.forward(state)\n",
        "        m = Categorical(probs)\n",
        "        action = m.sample()\n",
        "        return action.item(), m.log_prob(action)"
      ],
      "metadata": {
        "id": "UpBN4q--G9Vi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Reinforce Training Algorithm\n",
        "\n",
        "Start with loop that collects an episode and saves it into a replay buffer"
      ],
      "metadata": {
        "id": "pWQTckwfG87F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_episode_data(policy):\n",
        "    data = [\n",
        "            np.empty((0, num_obs), dtype=np.float32), # obs\n",
        "            np.empty((0, 1), dtype=np.float32), # action\n",
        "            np.empty((0, 1), dtype=np.float32), # reward\n",
        "            np.empty((0, 1), dtype=bool),  # done\n",
        "            np.empty((0, num_obs), dtype=np.float32), # next_obs\n",
        "            ] \n",
        "\n",
        "    log_prob = []\n",
        "\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action, lp = policy.act(state)\n",
        "        log_prob.append(lp)\n",
        "        data[0] = np.append(data[0], np.reshape(state, (1,-1)), axis=0)\n",
        "        data[1] = np.append(data[1], np.reshape(action, (1,-1)), axis=0)\n",
        "        data[2] = np.append(data[2], np.reshape(reward, (1,-1)), axis=0)\n",
        "        data[3] = np.append(data[3], np.reshape(done, (1,-1)), axis=0)\n",
        "\n",
        "        state, reward, done, info = env.step(action)\n",
        "\n",
        "        data[4] = np.append(data[4], np.reshape(state, (1,-1)), axis=0)\n",
        "\n",
        "    # The final replay buffer idx won't have a \"next_state\" or \"action\"\n",
        "    data[0] = np.append(data[0], np.reshape(state, (1,-1)), axis=0)\n",
        "    data[2] = np.append(data[2], np.reshape(reward, (1,-1)), axis=0)\n",
        "    data[3] = np.append(data[3], np.reshape(done, (1,-1)), axis=0)\n",
        "\n",
        "    return data, log_prob\n",
        "\n",
        "## Debug printing\n",
        "# data, _ = generate_episode_data(policy)\n",
        "# for i in range(5):\n",
        "#     print(len(data[i]))\n",
        "# print(data)\n"
      ],
      "metadata": {
        "id": "W8y51ePjQPhD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next a function that takes the replay buffer and calculates cumulative reward"
      ],
      "metadata": {
        "id": "NY378FstV3r4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_cumulative_reward(data, gamma):\n",
        "    num_states = len(data[0])\n",
        "    cumulative_reward = np.empty((num_states, 1), dtype=np.float32)\n",
        "    cumulative_reward[num_states - 1] = data[2][num_states - 1]\n",
        "    for i in reversed(range(num_states-1)):\n",
        "        cumulative_reward[i] = data[2][i] + gamma * cumulative_reward[i + 1]\n",
        "\n",
        "    return cumulative_reward\n",
        "\n",
        "## For debugging\n",
        "# gamma = 0.99\n",
        "# data, _ = generate_episode_data(policy)\n",
        "# R = find_cumulative_reward(data, gamma)\n",
        "\n",
        "# for i in range(len(data[2])):\n",
        "#     print(\"[{}] r: {} cr: {}\".format(i, data[2][i], R[i]))"
      ],
      "metadata": {
        "id": "0u5dTE7eWbVA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes:**\n",
        "\n",
        "In the huggingface class G(t) is only calculated for the entire episode. Here we calculate G(t) for each state in the episode and sum them together.\n",
        "\n",
        "This trick is then used to increase performance found [in the pytorch reinforce implementation](https://github.com/pytorch/examples/blob/main/reinforcement_learning/reinforce.py)\n",
        "```\n",
        "R(t) = G(t) - mean(G(t)) / std(G(t))\n",
        "```\n"
      ],
      "metadata": {
        "id": "bzlz5kvf8Qgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_single_episode(optimizer, policy):\n",
        "    data, log_prob = generate_episode_data(policy)\n",
        "    R = find_cumulative_reward(data, gamma)\n",
        "\n",
        "    policy_losses = []\n",
        "    R = torch.tensor(R)\n",
        "\n",
        "    # This comes from the pytorch reinforce example\n",
        "    # https://github.com/pytorch/examples/blob/main/reinforcement_learning/reinforce.py\n",
        "    R = (R - R.mean()) / (R.std() + eps)\n",
        "    for r, l_p in zip(R, log_prob):\n",
        "        # Weird for me here that \n",
        "        policy_losses.append(-l_p * r)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    # Note here that div by the len seems to degrade performance\n",
        "    policy_loss = torch.cat(policy_losses).sum()# / len(data[0])\n",
        "\n",
        "    if log:\n",
        "        wandb.log({\"loss\": policy_loss})\n",
        "        wandb.log({\"reward sum\": np.sum(data[2])})\n",
        "        wandb.log({\"episode length\": len(data[0])})\n",
        "\n",
        "    policy_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    tensor_obs = torch.from_numpy(data[0])\n",
        "\n",
        "\n",
        "## Debug - Single Step\n",
        "# env_id = \"CartPole-v1\"\n",
        "# env = gym.make(env_id)\n",
        "\n",
        "# num_obs = env.observation_space.shape[0]\n",
        "# num_act = env.action_space.n\n",
        "\n",
        "# policy = PolicyNetwork(num_obs, num_act)\n",
        "# optimizer = optim.Adam(policy.parameters(), lr=1e-2)\n",
        "# # eps = np.finfo(np.float32).eps.item()\n",
        "\n",
        "# train_single_episode(optimizer, policy)"
      ],
      "metadata": {
        "id": "3p7jLTIwcyuw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(env_id):\n",
        "    if log: \n",
        "        wandb.init(project=\"reinforce\")\n",
        "    env = gym.make(env_id)\n",
        "\n",
        "    num_obs = env.observation_space.shape[0]\n",
        "    num_act = env.action_space.n\n",
        "\n",
        "    policy = PolicyNetwork(num_obs, num_act)\n",
        "\n",
        "    if log: \n",
        "        wandb.watch(policy, log_freq=1)  \n",
        "\n",
        "    optimizer = optim.Adam(policy.parameters(), lr=1e-2)\n",
        "    # eps = np.finfo(np.float32).eps.item()\n",
        "\n",
        "    for i in range(1, steps):\n",
        "        if log:\n",
        "            wandb.log({\"epoch\": i})\n",
        "        train_single_episode(optimizer, policy)"
      ],
      "metadata": {
        "id": "za99UPdKICS9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discount factor\n",
        "gamma = 0.99\n",
        "steps = 500\n",
        "\n",
        "log = True\n",
        "eps = np.finfo(np.float32).eps.item()"
      ],
      "metadata": {
        "id": "W4--3IgQycPk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_id = \"CartPole-v1\"\n",
        "train(env_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "a8150e8249024d6ca524f16e50038033",
            "e64df972301441ddbe86aac7b5232a2f",
            "e7fc5b4efdc642c3ab32b41b4d967088",
            "652af0b54229403387bfed60d739d3c1",
            "d883f1908d834a4ebc0fbcf62c90ef7f",
            "4785554bed9144bf9a4f2f7b3154906c",
            "b6d6f3c439cf4359905f2beb921d6c90",
            "1679a6e98d8a494099afcce71e880eec"
          ]
        },
        "id": "VeNGLp4AyOY1",
        "outputId": "3c95138a-e411-47de-ea75-db1f6d5e35b8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:2pek3g3i) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8150e8249024d6ca524f16e50038033"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>episode length</td><td>▁▂▃▂█▅▃▄██▄▂▇█▃▃▇█▇███▆█▆█▂▅█▅██████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▆▆▄█▄▅▆▃▅▅▅▅▆▄▇▇▆▆▄▆▅▂▄▆▆▅▅█▅▆▁▄▃▆▆▄▅▃▅▄</td></tr><tr><td>reward sum</td><td>▁▂▃▂█▅▃▄██▄▂▇█▃▃▇█▇███▆█▆█▂▅█▅██████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>episode length</td><td>501</td></tr><tr><td>epoch</td><td>999</td></tr><tr><td>loss</td><td>-0.01161</td></tr><tr><td>reward sum</td><td>500.0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">noble-aardvark-8</strong>: <a href=\"https://wandb.ai/jefsnacker/reinforce/runs/2pek3g3i\" target=\"_blank\">https://wandb.ai/jefsnacker/reinforce/runs/2pek3g3i</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220805_120824-2pek3g3i/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:2pek3g3i). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220805_121342-3mgjfjbu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/jefsnacker/reinforce/runs/3mgjfjbu\" target=\"_blank\">crisp-microwave-9</a></strong> to <a href=\"https://wandb.ai/jefsnacker/reinforce\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}